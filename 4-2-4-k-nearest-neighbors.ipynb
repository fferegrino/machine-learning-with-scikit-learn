{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad9becf",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors\n",
    "\n",
    "Otra forma de clasificar elementos es a través del algoritmo de k-Nearest Neighbors. Este funciona clasificando los datos basándose a las etiquetas de los datos que tiene más cercanos en el espacio de características – para cada una nueva muestra se buscan los “k” vecinos más cercanos y dependiendo de estas etiquetas se decide a que clase pertenece dada nuevo elemento.\n",
    "\n",
    "La forma de utilizarlo en scikit-learn es simple como cualquier otro clasificador, lo importamos del módulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9876c",
   "metadata": {},
   "source": [
    "Y tiene los métodos <code>fit</code> y <code>predict</code> usuales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples=1000, random_state=42, noise=0.1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64181bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(knn.predict(X_test))\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb16bed",
   "metadata": {},
   "source": [
    "Y también tiene el método <code>predict_proba</code> aunque la probabilidad aquí nos ayuda a definir cuantos vecinos cercanos tenía: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn.predict_proba(X_test)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74646d9",
   "metadata": {},
   "source": [
    "Como sea, lo interesante está en los argumentos, los hiperparámetros de la clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b11f4",
   "metadata": {},
   "source": [
    "## Argumentos\n",
    "\n",
    "Al igual que muchos otros modelos de machine learning, la clase <code>KNeighborsClassifier</code> tiene algunos argumentos para modificar su comportamiento:\n",
    "\n",
    " - <code>n_neighbors</code>: Este hiperparámetro determina la cantidad de vecinos que se utilizarán en la clasificación. Si el valor de <code>n_neighbors</code> es demasiado bajo, el modelo puede sobreajustar los datos, mientras que si el valor es demasiado alto, el modelo puede subajustar los datos. El valor por default 5.\n",
    "\n",
    " - <code>weights</code>: Este hiperparámetro determina cómo se ponderan las distancias entre las muestras de entrenamiento y la muestra de prueba. Las opciones son 'uniform', donde todas las muestras tienen el mismo peso en la clasificación, y 'distance', donde las muestras más cercanas tienen un mayor peso. Usualmente, la opción por defecto es 'uniform'.\n",
    "\n",
    " - <code>metric</code>: Este hiperparámetro determina la métrica de distancia utilizada para calcular las distancias entre las muestras. Algunas opciones comunes son 'euclidean', 'manhattan' y 'minkowski'.\n",
    "\n",
    " - <code>algorithm</code>: Este hiperparámetro determina el algoritmo utilizado para encontrar los vecinos más cercanos. Las opciones son 'brute', que busca los vecinos más cercanos calculando todas las distancias entre todas las muestras, y 'kd_tree' o 'ball_tree', que utilizan estructuras de datos para buscar los vecinos más cercanos de manera más eficiente.\n",
    "\n",
    "Vamos a ver el comportamiento del modelo cuando modificamos su , comenzando por la que tal vez sea la más importante:\n",
    "\n",
    "Primero vamos a crear un dataset de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd063859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_boundaries\n",
    "\n",
    "X, y = make_moons(n_samples=1000, random_state=42, noise=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ead054",
   "metadata": {},
   "source": [
    "## <code>n_neighbors</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd882f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundaries(\n",
    "    X, y, \n",
    "    [\n",
    "        ('n_neighbors = 1', KNeighborsClassifier(n_neighbors=1)),\n",
    "        ('n_neighbors = 10', KNeighborsClassifier(n_neighbors=10)),\n",
    "        ('n_neighbors = 100', KNeighborsClassifier(n_neighbors=100)),\n",
    "        ('n_neighbors = 999', KNeighborsClassifier(n_neighbors=999)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eee9c0",
   "metadata": {},
   "source": [
    "## La importancia de escalar las características\n",
    "\n",
    "k-Nearest Neighbors es un algoritmo basado completamente en las distancias entre características, es de vital importancia que estas estén escaladas antes de pasarlas al modelo, si no, vas a sufrir de problemas al momento de entrenar y obtener predicciones.\n",
    "\n",
    "Para demostrarlo, aquí estoy creando un dataset y estoy sacando una de sus características fuera de la escala al multiplicarla por 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=100, random_state=42, noise=.1)\n",
    "X[:,1] = X[:,1] * 5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a587e47",
   "metadata": {},
   "source": [
    "Después entreno un dataset con los datos sin escalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83506c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_unscaled = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_unscaled.fit(X_train, y_train)\n",
    "accuracy_unscaled = knn_unscaled.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c397b",
   "metadata": {},
   "source": [
    "Y entreno uno escalando las características previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af32644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "knn_scaled = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_scaled.fit(X_train_scaled, y_train)\n",
    "accuracy_scaled = knn_scaled.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66883c34",
   "metadata": {},
   "source": [
    "De entrada podemos ver la diferencia entre el desempeño de uno y otro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faec7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sin escalar\\t{accuracy_unscaled:.4f}\")\n",
    "print(f\"Escaladas\\t{accuracy_scaled:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6b441f",
   "metadata": {},
   "source": [
    "Pero se ve puede apreciar mejor con una gráfica en dos dimensiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079edd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_knn_boundaries\n",
    "\n",
    "plot_knn_boundaries(knn_unscaled,knn_scaled, X_train, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff446ae1",
   "metadata": {},
   "source": [
    "## Tamaño\n",
    "\n",
    "El tamaño de un modelo de kNN en disco y en memoria varía con respecto al tamaño de su dataset de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b5d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "n_samples = [100, 1000, 10000, 100000]\n",
    "\n",
    "for n in n_samples:\n",
    "    X, y = make_classification(n_samples=n, n_features=20)\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X, y)\n",
    "    joblib.dump(knn, f\"/tmp/knn_model_{n}.joblib\")\n",
    "    model_size = os.path.getsize(f\"/tmp/knn_model_{n}.joblib\")\n",
    "\n",
    "    print(f\"Tamaño del modelo (n={n}):\\t{model_size:>10} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1fcf47",
   "metadata": {},
   "source": [
    "## En conclusión\n",
    "\n",
    "El modelo de k-NN es uno que puedes utilizar en problemas de clasificación, especialmente en conjuntos de datos pequeños o de tamaño moderado, problemas con múltiples clases, datos ruidosos o valores faltantes, y en problemas con una dimensionalidad baja a moderada.\n",
    "\n",
    "Pero considera no utilizarlo en problemas con conjuntos de datos grandes, problemas con una dimensionalidad alta, problemas en los que la velocidad es crítica, problemas con datos muy dispersos, y en problemas en los que la precisión es más importante que la simplicidad y la interpretabilidad. En estos casos, puede ser necesario considerar otros algoritmos de aprendizaje automático más adecuados para el problema específico.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "notion_metadata": {
   "archived": false,
   "cover": null,
   "created_by": {
    "id": "84951847-6e2b-487e-acba-6838f60f1102",
    "object": "user"
   },
   "created_time": "2023-03-14T20:32:00.000Z",
   "icon": null,
   "id": "48ca8b03-f148-42a3-a5a1-2c88cf4b4e6e",
   "last_edited_by": {
    "id": "84951847-6e2b-487e-acba-6838f60f1102",
    "object": "user"
   },
   "last_edited_time": "2023-04-23T09:31:00.000Z",
   "object": "page",
   "parent": {
    "database_id": "97ecfa4e-50d1-4827-8791-2199c709d680",
    "type": "database_id"
   },
   "properties": {
    "Assign": {
     "id": "%5DtZZ",
     "people": [],
     "type": "people"
    },
    "Code name": {
     "id": "PT%5CP",
     "rich_text": [
      {
       "annotations": {
        "bold": false,
        "code": false,
        "color": "default",
        "italic": false,
        "strikethrough": false,
        "underline": false
       },
       "href": null,
       "plain_text": "kNN",
       "text": {
        "content": "kNN",
        "link": null
       },
       "type": "text"
      }
     ],
     "type": "rich_text"
    },
    "Name": {
     "id": "title",
     "title": [
      {
       "annotations": {
        "bold": false,
        "code": false,
        "color": "default",
        "italic": false,
        "strikethrough": false,
        "underline": false
       },
       "href": null,
       "plain_text": "4.2.4 k-Nearest neighbors",
       "text": {
        "content": "4.2.4 k-Nearest neighbors",
        "link": null
       },
       "type": "text"
      }
     ],
     "type": "title"
    },
    "Order": {
     "id": "k_Cb",
     "number": 5.24,
     "type": "number"
    },
    "Real order": {
     "id": "%7Dn_k",
     "rich_text": [
      {
       "annotations": {
        "bold": false,
        "code": false,
        "color": "default",
        "italic": false,
        "strikethrough": false,
        "underline": false
       },
       "href": null,
       "plain_text": "25",
       "text": {
        "content": "25",
        "link": null
       },
       "type": "text"
      }
     ],
     "type": "rich_text"
    },
    "Status": {
     "id": "s%7D%5Ea",
     "status": {
      "color": "green",
      "id": "b6060d48-45e7-42e9-a8a0-8bd803231f7f",
      "name": "Done"
     },
     "type": "status"
    }
   },
   "url": "https://www.notion.so/4-2-4-k-Nearest-neighbors-48ca8b03f14842a3a5a12c88cf4b4e6e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
